{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GAN for Generating shirt designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        with h5py.File(\"cell_data.h5\", \"r\") as data:\n",
    "            self.train_images = [data[\"/train_image_{}\".format(i)][:] for i in range(28)]\n",
    "            self.train_labels = [data[\"/train_label_{}\".format(i)][:] for i in range(28)]\n",
    "            self.test_images = [data[\"/test_image_{}\".format(i)][:] for i in range(3)]\n",
    "            self.test_labels = [data[\"/test_label_{}\".format(i)][:] for i in range(3)]\n",
    "\n",
    "        self.input_resolution = 300\n",
    "        self.label_resolution = 116\n",
    "\n",
    "        self.offset = (300 - 116) // 2\n",
    "        \n",
    "\n",
    "    def get_train_image_list_and_label_list(self):\n",
    "        n = random.randint(0, len(self.train_images) - 1)\n",
    "        x = random.randint(0, (self.train_images[n].shape)[1] - self.input_resolution - 1)\n",
    "        y = random.randint(0, (self.train_images[n].shape)[0] - self.input_resolution - 1)\n",
    "        image = self.train_images[n][y:y + self.input_resolution, x:x + self.input_resolution, :]\n",
    "\n",
    "        x += self.offset\n",
    "        y += self.offset\n",
    "        label = self.train_labels[n][y:y + self.label_resolution, x:x + self.label_resolution]\n",
    "\n",
    "        return [image], [label]\n",
    "\n",
    "    def get_test_image_list_and_label_list(self):\n",
    "        coord_list = [[0,0], [0, 116], [0, 232], \n",
    "                  [116,0], [116, 116], [116, 232],\n",
    "                  [219,0], [219, 116], [219, 232]]\n",
    "\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "    \n",
    "        for image_id in range(3):\n",
    "            for y, x in coord_list:\n",
    "                image = self.test_images[image_id][y:y + self.input_resolution, x:x + self.input_resolution, :]\n",
    "                image_list.append(image)\n",
    "                x += self.offset\n",
    "                y += self.offset\n",
    "                label = self.test_labels[image_id][y:y + self.label_resolution, x:x + self.label_resolution]\n",
    "                label_list.append(label)\n",
    "    \n",
    "\n",
    "        return image_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "redImage = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "for x in range(300):\n",
    "    for y in range(300):\n",
    "        redImage[x, y] = [random.randint(0, 255), random.randint(1, 70), random.randint(1, 70)]\n",
    "img = Image.fromarray(redImage, 'RGB')\n",
    "img.show()\n",
    "\n",
    "orangeImage = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "for x in range(300):\n",
    "    for y in range(300):\n",
    "        orangeImage[x, y] = [random.randint(0, 255), random.randint(0, 150), random.randint(0, 50)]\n",
    "img = Image.fromarray(orangeImage, 'RGB')\n",
    "img.show()\n",
    "trainData = [(redImage, [1, 0]), (orangeImage, [0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRandomTrainImageAndLabel(data):\n",
    "    test_image_and_label = data.get_train_image_list_and_label_list()\n",
    "    randomInt = np.random.randint(0, len(test_image_and_label[0]))\n",
    "    train_image = test_image_and_label[0][randomInt].reshape((1, 300, 300))\n",
    "    train_label = test_image_and_label[1][randomInt]\n",
    "    return train_image, train_label\n",
    "\n",
    "def getRandomTestImageAndLabel(data):\n",
    "    test_image_and_label = data.get_test_image_list_and_label_list()\n",
    "    randomInt = np.random.randint(0, len(test_image_and_label[0]))\n",
    "    test_image = test_image_and_label[0][randomInt].reshape((1, 300, 300))\n",
    "    test_label = test_image_and_label[1][randomInt]\n",
    "    return test_image, test_label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predefined functions to add noise to initial values of weights and biases\n",
    "def weight_variable(shape):\n",
    "    initial = tf.glorot_uniform_initializer()\n",
    "    return tf.Variable(initial(shape))\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.zeros.initializer()\n",
    "    return tf.Variable(initial(shape))\n",
    "\n",
    "# predefined conv and pool layers with stride and padding set\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, filter=W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "\n",
    "# predefined transposed convolution layer\n",
    "def conv2d_transposed(x, filters): \n",
    "    return tf.layers.conv2d_transpose(inputs=x, filters=filters, \n",
    "                                      kernel_size=[2, 2], strides=[2, 2], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualizeImage(image):\n",
    "    \"\"\" Plots one image. Only works with square shaped images formatted as in the cell data file.\"\"\"\n",
    "    image = image.reshape((image.shape[1], image.shape[1]))\n",
    "    size = len(image)\n",
    "    label = image\n",
    "    label_pixels = np.array(label).reshape((size, size))\n",
    "    # plt.title('Original image')\n",
    "    plt.imshow(label_pixels, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Discriminator(input_images):\n",
    "    \"\"\" An CNN that labels a skalar probability that an image is a real cell image. \n",
    "    300x300x1 -> 1x1x2 \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope('reshaping'):\n",
    "        x_reshaped = tf.reshape(input_images, [-1, 300, 300, 1])\n",
    "\n",
    "    \n",
    "    # convolutional layer, result shape: 298x298, 32 filters --------------------------------------\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([3, 3, 1, 32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_reshaped, W_conv1))\n",
    "        \n",
    "        \n",
    "    # convolutional layer, result shape: 296x296, 32 filters\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([3, 3, 32, 32])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2))\n",
    "\n",
    "\n",
    "    # max pool layer, result shape: 148x148, 32 filters\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv2)\n",
    "    \n",
    "    \n",
    "    # convolutional layer, result shape: 146x146, 64 filters --------------------------------------\n",
    "    with tf.name_scope('conv3'):\n",
    "        W_conv3 = weight_variable([3, 3, 32, 64])\n",
    "        h_conv3 = tf.nn.relu(conv2d(h_pool1, W_conv3))\n",
    "        \n",
    "        \n",
    "    # convolutional layer, result shape: 144x144, 64 filters\n",
    "    with tf.name_scope('conv4'):\n",
    "        W_conv4 = weight_variable([3, 3, 64, 64])\n",
    "        h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4))\n",
    "\n",
    "\n",
    "    # max pool layer, result shape: 72x72, 64 filters\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv4)\n",
    "    \n",
    "    \n",
    "    # convolutional layer, result shape: 70x70, 128 filters --------------------------------------\n",
    "    with tf.name_scope('conv5'):\n",
    "        W_conv5 = weight_variable([3, 3, 64, 128])\n",
    "        h_conv5 = tf.nn.relu(conv2d(h_pool2, W_conv5))\n",
    "        \n",
    "        \n",
    "    # convolutional layer, result shape: 68x68, 128 filters\n",
    "    with tf.name_scope('conv6'):\n",
    "        W_conv6 = weight_variable([3, 3, 128, 128])\n",
    "        h_conv6 = tf.nn.relu(conv2d(h_conv5, W_conv6))\n",
    "\n",
    "\n",
    "    # max pool layer, result shape: 34x34, 128 filters\n",
    "    with tf.name_scope('pool3'):\n",
    "        h_pool3 = max_pool_2x2(h_conv6)\n",
    "    \n",
    "    \n",
    "    # convolutional layer, result shape: 32x32, 256 filters --------------------------------------\n",
    "    with tf.name_scope('conv7'):\n",
    "        W_conv7 = weight_variable([3, 3, 128, 256])\n",
    "        h_conv7 = tf.nn.relu(conv2d(h_pool3, W_conv7))\n",
    "        \n",
    "        \n",
    "    # convolutional layer, result shape: 30x30, 256 filters\n",
    "    with tf.name_scope('conv8'):\n",
    "        W_conv8 = weight_variable([3, 3, 256, 256])\n",
    "        h_conv8 = tf.nn.relu(conv2d(h_conv7, W_conv8))\n",
    "\n",
    "\n",
    "    # max pool layer, result shape: 15x15, 256 filters\n",
    "    with tf.name_scope('pool4'):\n",
    "        h_pool4 = max_pool_2x2(h_conv8)\n",
    "    \n",
    "    \n",
    "    # convolutional layer, result shape: 13x13, 512 filters --------------------------------------     \n",
    "    with tf.name_scope('conv9'):\n",
    "        W_conv9 = weight_variable([3, 3, 256, 512])\n",
    "        h_conv9 = tf.nn.relu(conv2d(h_pool4, W_conv9))\n",
    "        \n",
    "        \n",
    "    # convolutional layer, result shape: 11x11, 512 filters\n",
    "    with tf.name_scope('conv10'):\n",
    "        W_conv10 = weight_variable([3, 3, 512, 512])\n",
    "        h_conv10 = tf.nn.relu(conv2d(h_conv9, W_conv10))\n",
    "        \n",
    "        \n",
    "    # max pool layer, result shape: 5x5, 512 filters\n",
    "    with tf.name_scope('pool5'):\n",
    "        h_pool5 = max_pool_2x2(h_conv10)\n",
    "        \n",
    "        \n",
    "    # convolutional layer, result shape: 3x3, 1024 filters --------------------------------------     \n",
    "    with tf.name_scope('conv11'):\n",
    "        W_conv11 = weight_variable([3, 3, 512, 1024])\n",
    "        h_conv11 = tf.nn.relu(conv2d(h_pool5, W_conv11))\n",
    "        \n",
    "        \n",
    "    # convolutional layer, result shape: 1x1, 1024 filters\n",
    "    with tf.name_scope('conv12'):\n",
    "        W_conv12 = weight_variable([3, 3, 1024, 1024])\n",
    "        h_conv12 = tf.nn.relu(conv2d(h_conv11, W_conv12))\n",
    "        \n",
    "        \n",
    "    # flatten to be able to fully connect\n",
    "    with tf.name_scope('flatten'):    \n",
    "        h_conv12_flat = tf.reshape(h_conv12, [-1, 1 * 1 * 1024])\n",
    "    \n",
    "    # fc layer, result shape: 1x1, 256 filters\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([1024, 256])\n",
    "        b_fc1 = bias_variable([256])\n",
    "        y_fc1 = tf.matmul(h_conv12_flat, W_fc1) + b_fc1\n",
    "        \n",
    "        \n",
    "    # fc layer, result shape: 1x1, 2 filters\n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([256, 2])\n",
    "        b_fc2 = bias_variable([2])\n",
    "        y_fc2 = tf.matmul(y_fc1, W_fc2) + b_fc2\n",
    "    \n",
    "    \n",
    "    return y_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainAndTestNet(epochs, restore=False):\n",
    "    # Placeholder for input\n",
    "    x = tf.placeholder(tf.float32, [None, 300, 300])\n",
    "    \n",
    "    # Placeholder for label \n",
    "    labels = tf.constant([1, 1, 0], dtype=tf.float32)\n",
    "    \n",
    "    # Placeholder for output\n",
    "    y = Discriminator(x)\n",
    "    # TODO delete\n",
    "    y_flat = tf.reshape(y, [-1, -1, 2])\n",
    "    \n",
    "    # Calculate loss from original image\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=y_flat)\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "    tf.summary.scalar('loss', loss)\n",
    "    \n",
    "    # optimize loss with the AdamOptimizer\n",
    "    with tf.name_scope(\"AdamOptimizer\"):\n",
    "        train_step = tf.train.AdamOptimizer(0.0001, 0.95, 0.99).minimize(loss)\n",
    "        \n",
    "        \n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        if not restore:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            writer = tf.summary.FileWriter('C:/Users/Kai/', graph=sess.graph)\n",
    "            for epoch in range(epochs):\n",
    "                    train_image, train_label = getRandomTrainImageAndLabel(data)\n",
    "\n",
    "                    if epoch % 1000 == 0:\n",
    "    \n",
    "                        # evaluate loss for the testing data\n",
    "                        train_loss = loss.eval(feed_dict={x: train_image})\n",
    "                        \n",
    "                        print('step %d, training loss %0.3f' % (epoch, train_loss))\n",
    "                    \n",
    "                    train_step.run(feed_dict={x: train_image})\n",
    "\n",
    "                    # collect data for summary\n",
    "                    summary_str = sess.run(merged_summary_op, feed_dict={x: train_image, labels: train_label})\n",
    "                    writer.add_summary(summary_str, epoch)\n",
    "            save_path = saver.save(sess, \"C:/Users/Kai/\" + str(epochs) + \"/model.ckpt\")\n",
    "        else:\n",
    "            saver.restore(sess, \"C:Users/Kai/DeepLearningLab/Project4/model/20000/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'initializer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-459e6ed56fac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainAndTestNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-361beaab86a6>\u001b[0m in \u001b[0;36mtrainAndTestNet\u001b[1;34m(epochs, restore)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Placeholder for output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# TODO delete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0my_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-04d984202a4c>\u001b[0m in \u001b[0;36mDiscriminator\u001b[1;34m(input_images)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fc1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mW_fc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mb_fc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbias_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0my_fc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_conv12_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_fc1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_fc1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d3742724290e>\u001b[0m in \u001b[0;36mbias_variable\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbias_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0minitial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'initializer'"
     ]
    }
   ],
   "source": [
    "trainAndTestNet(40000, restore=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
